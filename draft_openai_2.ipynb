{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (1.74.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: ipywidgets in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (8.1.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipywidgets) (9.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: colorama in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# If running in a notebook for the first time:\n",
    "%pip install openai python-dotenv ipywidgets \n",
    "# --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83036f552c84850b22316b96108f559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='▶️ Action:', layout=Layout(width='70%'), placeholder='What does Ihno do next?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599feeaaedaa44c1bcd9398244eb421b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdcf3732f4a446408a04f07023ff89a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mgenerate_story\u001b[39m\u001b[34m(context, player_input, difficulty)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Use openai.Completion.create for OpenAI API >= 1.0.0\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.95\u001b[39;49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].text.strip()  \u001b[38;5;66;03m# Updated to use .text for the response\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 111\u001b[39m, in \u001b[36mon_button_click\u001b[39m\u001b[34m(b)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_button_click\u001b[39m(b):\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m     \u001b[43mplay_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_box\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m     input_box.value = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 78\u001b[39m, in \u001b[36mplay_turn\u001b[39m\u001b[34m(player_input)\u001b[39m\n\u001b[32m     75\u001b[39m adjust_difficulty(player_input)\n\u001b[32m     77\u001b[39m recent_context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(game_memory[-\u001b[32m6\u001b[39m:])\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m new_story = \u001b[43mgenerate_story\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecent_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdifficulty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m context_update = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mplayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnew_story\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     80\u001b[39m context += context_update\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mgenerate_story\u001b[39m\u001b[34m(context, player_input, difficulty)\u001b[39m\n\u001b[32m     49\u001b[39m     response = openai.Completion.create(\n\u001b[32m     50\u001b[39m         model=model_name,\n\u001b[32m     51\u001b[39m         prompt=prompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m         top_p=\u001b[32m0.95\u001b[39m\n\u001b[32m     55\u001b[39m     )\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].text.strip()  \u001b[38;5;66;03m# Updated to use .text for the response\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m.RateLimitError:\n\u001b[32m     58\u001b[39m     time.sleep(\u001b[32m2\u001b[39m ** attempt)  \u001b[38;5;66;03m# Exponential backoff for rate limiting\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'openai' has no attribute 'error'"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# --- LOAD API KEY ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY not found in .env file!\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "# --- GAME STATE ---\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "player_name = \"Ihno\"\n",
    "context = \"\"\n",
    "game_memory = []\n",
    "player_stats = {}\n",
    "inventory = []\n",
    "difficulty = 1\n",
    "\n",
    "# --- DIFFICULTY ADJUSTMENT ---\n",
    "def adjust_difficulty(player_input):\n",
    "    global difficulty\n",
    "    if any(word in player_input.lower() for word in [\"attack\", \"fight\", \"battle\"]):\n",
    "        difficulty = min(difficulty + 1, 5)\n",
    "    elif any(word in player_input.lower() for word in [\"run\", \"talk\", \"hide\"]):\n",
    "        difficulty = max(difficulty - 1, 1)\n",
    "    return difficulty\n",
    "\n",
    "# --- STORY GENERATION --- (Updated)\n",
    "def generate_story(context, player_input, difficulty):\n",
    "    prompt = (\n",
    "        \"You are a fantasy storytelling AI. \"\n",
    "        \"Continue the adventure in a vivid, immersive style. \"\n",
    "        f\"Difficulty level: {difficulty}.\\n\\n\"\n",
    "        f\"{context}\\n\"\n",
    "        f\"{player_name}: {player_input}\\n\"\n",
    "        \"Narrator:\"\n",
    "    )\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            # Use openai.Completion.create for OpenAI API >= 1.0.0\n",
    "            response = openai.Completion.create(\n",
    "                model=model_name,\n",
    "                prompt=prompt,\n",
    "                max_tokens=150,\n",
    "                temperature=0.9,\n",
    "                top_p=0.95\n",
    "            )\n",
    "            return response.choices[0].text.strip()  # Updated to use .text for the response\n",
    "        except openai.error.RateLimitError:\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff for rate limiting\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error generating story: {e}\"\n",
    "    return \"⚠️ The story could not be continued due to repeated errors.\"\n",
    "\n",
    "# --- PRINT GAME STATE ---\n",
    "def print_game_state():\n",
    "    display(Markdown(f\"### 📖 **Story so far**\\n{context}\"))\n",
    "    display(Markdown(f\"**🧍 {player_name}'s Inventory:** {inventory}\"))\n",
    "    display(Markdown(f\"**❤️ Stats:** {player_stats} | 🎯 Difficulty:** {['Easy', 'Medium', 'Hard', 'Very Hard', 'Nightmare'][difficulty - 1]}\"))\n",
    "\n",
    "# --- PLAY TURN ---\n",
    "def play_turn(player_input):\n",
    "    global context\n",
    "    if not player_input.strip():\n",
    "        return\n",
    "    game_memory.append(f\"{player_name}: {player_input}\")\n",
    "    adjust_difficulty(player_input)\n",
    "\n",
    "    recent_context = \"\\n\".join(game_memory[-6:])\n",
    "    new_story = generate_story(recent_context, player_input, difficulty)\n",
    "    context_update = f\"\\n{player_name}: {player_input}\\n{new_story}\"\n",
    "    context += context_update\n",
    "    game_memory.append(new_story)\n",
    "\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print_game_state()\n",
    "\n",
    "# --- START GAME ---\n",
    "def start_new_game():\n",
    "    global context, player_stats, inventory, difficulty, game_memory\n",
    "    context = f\"{player_name} awakens in a dark forest. A mysterious figure approaches.\"\n",
    "    game_memory = [context]\n",
    "    player_stats = {\"health\": 100, \"strength\": 10, \"gold\": 5}\n",
    "    inventory = [\"torch\"]\n",
    "    difficulty = 1\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(Markdown(\"🆕 **New game started.**\"))\n",
    "        print_game_state()\n",
    "\n",
    "# --- UI SETUP ---\n",
    "input_box = widgets.Text(\n",
    "    placeholder='What does Ihno do next?',\n",
    "    description='▶️ Action:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Submit\", button_style='success')\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    play_turn(input_box.value)\n",
    "    input_box.value = ''\n",
    "\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# Display all widgets\n",
    "start_new_game()\n",
    "display(input_box, submit_button, output_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeersel 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (1.74.0)\n",
      "Collecting openai\n",
      "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
      "   ---------------------------------------- 0.0/662.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 662.0/662.0 kB 12.9 MB/s eta 0:00:00\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.74.0\n",
      "    Uninstalling openai-1.74.0:\n",
      "      Successfully uninstalled openai-1.74.0\n",
      "Successfully installed openai-1.77.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61497254d4e40c8bb341772d82d5ed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='▶️ Action:', layout=Layout(width='70%'), placeholder='What does Ihno do next?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569eb524163e45a4b5fbccaf25d31d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b41cb2ba0ce4c04a91b45637ecb8175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'openai' has no attribute 'error'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mgenerate_story\u001b[39m\u001b[34m(context, player_input, difficulty)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# Use the new `openai.Chat.create` for the updated API\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChat\u001b[49m.create(\n\u001b[32m     50\u001b[39m         model=model_name,\n\u001b[32m     51\u001b[39m         messages=[\n\u001b[32m     52\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     53\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: prompt}\n\u001b[32m     54\u001b[39m         ],\n\u001b[32m     55\u001b[39m         max_tokens=\u001b[32m150\u001b[39m,\n\u001b[32m     56\u001b[39m         temperature=\u001b[32m0.9\u001b[39m,\n\u001b[32m     57\u001b[39m         top_p=\u001b[32m0.95\u001b[39m\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m].strip()  \u001b[38;5;66;03m# Updated for new API format\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: module 'openai' has no attribute 'Chat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mon_button_click\u001b[39m\u001b[34m(b)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mon_button_click\u001b[39m(b):\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mplay_turn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_box\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     input_box.value = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mplay_turn\u001b[39m\u001b[34m(player_input)\u001b[39m\n\u001b[32m     78\u001b[39m adjust_difficulty(player_input)\n\u001b[32m     80\u001b[39m recent_context = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(game_memory[-\u001b[32m6\u001b[39m:])\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m new_story = \u001b[43mgenerate_story\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecent_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplayer_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdifficulty\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m context_update = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mplayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnew_story\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     83\u001b[39m context += context_update\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mgenerate_story\u001b[39m\u001b[34m(context, player_input, difficulty)\u001b[39m\n\u001b[32m     49\u001b[39m     response = openai.Chat.create(\n\u001b[32m     50\u001b[39m         model=model_name,\n\u001b[32m     51\u001b[39m         messages=[\n\u001b[32m   (...)\u001b[39m\u001b[32m     57\u001b[39m         top_p=\u001b[32m0.95\u001b[39m\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m].strip()  \u001b[38;5;66;03m# Updated for new API format\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m.RateLimitError:\n\u001b[32m     61\u001b[39m     time.sleep(\u001b[32m2\u001b[39m ** attempt)  \u001b[38;5;66;03m# Exponential backoff for rate limiting\u001b[39;00m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mAttributeError\u001b[39m: module 'openai' has no attribute 'error'"
     ]
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# --- LOAD API KEY ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY not found in .env file!\")\n",
    "openai.api_key = api_key\n",
    "\n",
    "# --- GAME STATE ---\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "player_name = \"Ihno\"\n",
    "context = \"\"\n",
    "game_memory = []\n",
    "player_stats = {}\n",
    "inventory = []\n",
    "difficulty = 1\n",
    "\n",
    "# --- DIFFICULTY ADJUSTMENT ---\n",
    "def adjust_difficulty(player_input):\n",
    "    global difficulty\n",
    "    if any(word in player_input.lower() for word in [\"attack\", \"fight\", \"battle\"]):\n",
    "        difficulty = min(difficulty + 1, 5)\n",
    "    elif any(word in player_input.lower() for word in [\"run\", \"talk\", \"hide\"]):\n",
    "        difficulty = max(difficulty - 1, 1)\n",
    "    return difficulty\n",
    "\n",
    "# --- STORY GENERATION --- (Updated for v1.0.0)\n",
    "def generate_story(context, player_input, difficulty):\n",
    "    prompt = (\n",
    "        \"You are a fantasy storytelling AI. \"\n",
    "        \"Continue the adventure in a vivid, immersive style. \"\n",
    "        f\"Difficulty level: {difficulty}.\\n\\n\"\n",
    "        f\"{context}\\n\"\n",
    "        f\"{player_name}: {player_input}\\n\"\n",
    "        \"Narrator:\"\n",
    "    )\n",
    "    \n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            # Use the new `openai.Chat.create` for the updated API\n",
    "            response = openai.Chat.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                max_tokens=150,\n",
    "                temperature=0.9,\n",
    "                top_p=0.95\n",
    "            )\n",
    "            return response[\"choices\"][0][\"message\"][\"content\"].strip()  # Updated for new API format\n",
    "        except openai.error.RateLimitError:\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff for rate limiting\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error generating story: {e}\"\n",
    "    return \"⚠️ The story could not be continued due to repeated errors.\"\n",
    "\n",
    "# --- PRINT GAME STATE ---\n",
    "def print_game_state():\n",
    "    display(Markdown(f\"### 📖 **Story so far**\\n{context}\"))\n",
    "    display(Markdown(f\"**🧍 {player_name}'s Inventory:** {inventory}\"))\n",
    "    display(Markdown(f\"**❤️ Stats:** {player_stats} | 🎯 Difficulty:** {['Easy', 'Medium', 'Hard', 'Very Hard', 'Nightmare'][difficulty - 1]}\"))\n",
    "\n",
    "# --- PLAY TURN ---\n",
    "def play_turn(player_input):\n",
    "    global context\n",
    "    if not player_input.strip():\n",
    "        return\n",
    "    game_memory.append(f\"{player_name}: {player_input}\")\n",
    "    adjust_difficulty(player_input)\n",
    "\n",
    "    recent_context = \"\\n\".join(game_memory[-6:])\n",
    "    new_story = generate_story(recent_context, player_input, difficulty)\n",
    "    context_update = f\"\\n{player_name}: {player_input}\\n{new_story}\"\n",
    "    context += context_update\n",
    "    game_memory.append(new_story)\n",
    "\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print_game_state()\n",
    "\n",
    "# --- START GAME ---\n",
    "def start_new_game():\n",
    "    global context, player_stats, inventory, difficulty, game_memory\n",
    "    context = f\"{player_name} awakens in a dark forest. A mysterious figure approaches.\"\n",
    "    game_memory = [context]\n",
    "    player_stats = {\"health\": 100, \"strength\": 10, \"gold\": 5}\n",
    "    inventory = [\"torch\"]\n",
    "    difficulty = 1\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(Markdown(\"🆕 **New game started.**\"))\n",
    "        print_game_state()\n",
    "\n",
    "# --- UI SETUP ---\n",
    "input_box = widgets.Text(\n",
    "    placeholder='What does Ihno do next?',\n",
    "    description='▶️ Action:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Submit\", button_style='success')\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    play_turn(input_box.value)\n",
    "    input_box.value = ''\n",
    "\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# Display all widgets\n",
    "start_new_game()\n",
    "display(input_box, submit_button, output_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeersel 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c873009fe114f8bb302ea87ed2c9081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='▶️ Action:', layout=Layout(width='70%'), placeholder='What does Ihno do next?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e7728c96c124b809822c612f479e609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "114873c17a9147dd89f8aa2deb7f7708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import os\n",
    "import time\n",
    "from openai import OpenAI, OpenAIError, RateLimitError\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# --- LOAD API KEY ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ OPENAI_API_KEY not found in .env file!\")\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# --- GAME STATE ---\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "player_name = \"Ihno\"\n",
    "context = \"\"\n",
    "game_memory = []\n",
    "player_stats = {}\n",
    "inventory = []\n",
    "difficulty = 1\n",
    "\n",
    "# --- DIFFICULTY ADJUSTMENT ---\n",
    "def adjust_difficulty(player_input):\n",
    "    global difficulty\n",
    "    if any(word in player_input.lower() for word in [\"attack\", \"fight\", \"battle\"]):\n",
    "        difficulty = min(difficulty + 1, 5)\n",
    "    elif any(word in player_input.lower() for word in [\"run\", \"talk\", \"hide\"]):\n",
    "        difficulty = max(difficulty - 1, 1)\n",
    "    return difficulty\n",
    "\n",
    "# --- STORY GENERATION (OpenAI SDK v1) ---\n",
    "def generate_story(context, player_input, difficulty):\n",
    "    prompt = (\n",
    "        \"You are a fantasy storytelling AI. \"\n",
    "        \"Continue the adventure in a vivid, immersive style. \"\n",
    "        f\"Difficulty level: {difficulty}.\\n\\n\"\n",
    "        f\"{context}\\n\"\n",
    "        f\"{player_name}: {player_input}\\n\"\n",
    "        \"Narrator:\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=150,\n",
    "                temperature=0.9,\n",
    "                top_p=0.95\n",
    "            )\n",
    "            return response.choices[0].message.content.strip()\n",
    "        except RateLimitError:\n",
    "            time.sleep(2 ** attempt)\n",
    "        except OpenAIError as e:\n",
    "            return f\"❌ Error generating story: {e}\"\n",
    "\n",
    "    return \"⚠️ The story could not be continued due to repeated errors.\"\n",
    "\n",
    "# --- PRINT GAME STATE ---\n",
    "def print_game_state():\n",
    "    display(Markdown(f\"### 📖 **Story so far**\\n{context}\"))\n",
    "    display(Markdown(f\"**🧍 {player_name}'s Inventory:** {inventory}\"))\n",
    "    display(Markdown(f\"**❤️ Stats:** {player_stats} | 🎯 Difficulty:** {['Easy', 'Medium', 'Hard', 'Very Hard', 'Nightmare'][difficulty - 1]}\"))\n",
    "\n",
    "# --- PLAY TURN ---\n",
    "def play_turn(player_input):\n",
    "    global context\n",
    "    if not player_input.strip():\n",
    "        return\n",
    "    game_memory.append(f\"{player_name}: {player_input}\")\n",
    "    adjust_difficulty(player_input)\n",
    "\n",
    "    recent_context = \"\\n\".join(game_memory[-6:])\n",
    "    new_story = generate_story(recent_context, player_input, difficulty)\n",
    "    context_update = f\"\\n{player_name}: {player_input}\\n{new_story}\"\n",
    "    context += context_update\n",
    "    game_memory.append(new_story)\n",
    "\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print_game_state()\n",
    "\n",
    "# --- START GAME ---\n",
    "def start_new_game():\n",
    "    global context, player_stats, inventory, difficulty, game_memory\n",
    "    context = f\"{player_name} awakens in a dark forest. A mysterious figure approaches.\"\n",
    "    game_memory = [context]\n",
    "    player_stats = {\"health\": 100, \"strength\": 10, \"gold\": 5}\n",
    "    inventory = [\"torch\"]\n",
    "    difficulty = 1\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(Markdown(\"🆕 **New game started.**\"))\n",
    "        print_game_state()\n",
    "\n",
    "# --- UI SETUP ---\n",
    "input_box = widgets.Text(\n",
    "    placeholder='What does Ihno do next?',\n",
    "    description='▶️ Action:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Submit\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    play_turn(input_box.value)\n",
    "    input_box.value = ''\n",
    "\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# --- START & DISPLAY ---\n",
    "start_new_game()\n",
    "display(input_box, submit_button, output_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mopenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      3\u001b[39m client = OpenAI()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSay hello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(response.choices[\u001b[32m0\u001b[39m].message.content)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:279\u001b[39m, in \u001b[36mwrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:914\u001b[39m, in \u001b[36mcreate\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    655\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[33;03m    **Starting a new project?** We recommend trying\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[33;03m    [Responses](https://platform.openai.com/docs/api-reference/responses) to take\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    879\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    880\u001b[39m     ...\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    885\u001b[39m     *,\n\u001b[32m    886\u001b[39m     messages: Iterable[ChatCompletionMessageParam],\n\u001b[32m    887\u001b[39m     model: Union[\u001b[38;5;28mstr\u001b[39m, ChatModel],\n\u001b[32m    888\u001b[39m     audio: Optional[ChatCompletionAudioParam] | NotGiven = NOT_GIVEN,\n\u001b[32m    889\u001b[39m     frequency_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    890\u001b[39m     function_call: completion_create_params.FunctionCall | NotGiven = NOT_GIVEN,\n\u001b[32m    891\u001b[39m     functions: Iterable[completion_create_params.Function] | NotGiven = NOT_GIVEN,\n\u001b[32m    892\u001b[39m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mint\u001b[39m]] | NotGiven = NOT_GIVEN,\n\u001b[32m    893\u001b[39m     logprobs: Optional[\u001b[38;5;28mbool\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    894\u001b[39m     max_completion_tokens: Optional[\u001b[38;5;28mint\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    895\u001b[39m     max_tokens: Optional[\u001b[38;5;28mint\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    896\u001b[39m     metadata: Optional[Metadata] | NotGiven = NOT_GIVEN,\n\u001b[32m    897\u001b[39m     modalities: Optional[List[Literal[\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m]]] | NotGiven = NOT_GIVEN,\n\u001b[32m    898\u001b[39m     n: Optional[\u001b[38;5;28mint\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    899\u001b[39m     parallel_tool_calls: \u001b[38;5;28mbool\u001b[39m | NotGiven = NOT_GIVEN,\n\u001b[32m    900\u001b[39m     prediction: Optional[ChatCompletionPredictionContentParam] | NotGiven = NOT_GIVEN,\n\u001b[32m    901\u001b[39m     presence_penalty: Optional[\u001b[38;5;28mfloat\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    902\u001b[39m     reasoning_effort: Optional[ReasoningEffort] | NotGiven = NOT_GIVEN,\n\u001b[32m    903\u001b[39m     response_format: completion_create_params.ResponseFormat | NotGiven = NOT_GIVEN,\n\u001b[32m    904\u001b[39m     seed: Optional[\u001b[38;5;28mint\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    905\u001b[39m     service_tier: Optional[Literal[\u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mflex\u001b[39m\u001b[33m\"\u001b[39m]] | NotGiven = NOT_GIVEN,\n\u001b[32m    906\u001b[39m     stop: Union[Optional[\u001b[38;5;28mstr\u001b[39m], List[\u001b[38;5;28mstr\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m] | NotGiven = NOT_GIVEN,\n\u001b[32m    907\u001b[39m     store: Optional[\u001b[38;5;28mbool\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    908\u001b[39m     stream: Optional[Literal[\u001b[38;5;28;01mFalse\u001b[39;00m]] | Literal[\u001b[38;5;28;01mTrue\u001b[39;00m] | NotGiven = NOT_GIVEN,\n\u001b[32m    909\u001b[39m     stream_options: Optional[ChatCompletionStreamOptionsParam] | NotGiven = NOT_GIVEN,\n\u001b[32m    910\u001b[39m     temperature: Optional[\u001b[38;5;28mfloat\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    911\u001b[39m     tool_choice: ChatCompletionToolChoiceOptionParam | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m     tools: Iterable[ChatCompletionToolParam] | NotGiven = NOT_GIVEN,\n\u001b[32m    913\u001b[39m     top_logprobs: Optional[\u001b[38;5;28mint\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m     top_p: Optional[\u001b[38;5;28mfloat\u001b[39m] | NotGiven = NOT_GIVEN,\n\u001b[32m    915\u001b[39m     user: \u001b[38;5;28mstr\u001b[39m | NotGiven = NOT_GIVEN,\n\u001b[32m    916\u001b[39m     web_search_options: completion_create_params.WebSearchOptions | NotGiven = NOT_GIVEN,\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# Use the following arguments if you need to pass additional parameters to the API that aren't available via kwargs.\u001b[39;00m\n\u001b[32m    918\u001b[39m     \u001b[38;5;66;03m# The extra values given here take precedence over values defined on the client or passed to this method.\u001b[39;00m\n\u001b[32m    919\u001b[39m     extra_headers: Headers | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    920\u001b[39m     extra_query: Query | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    921\u001b[39m     extra_body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m    925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    926\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    927\u001b[39m         body=maybe_transform(\n\u001b[32m   (...)\u001b[39m\u001b[32m    970\u001b[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001b[32m    971\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1247\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m   1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n\u001b[32m   1241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpatch\u001b[39m(\n\u001b[32m   1242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1243\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   1244\u001b[39m     *,\n\u001b[32m   1245\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1246\u001b[39m     body: Body | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m     options: RequestOptions = {},\n\u001b[32m   1248\u001b[39m ) -> ResponseT:\n\u001b[32m   1249\u001b[39m     opts = FinalRequestOptions.construct(method=\u001b[33m\"\u001b[39m\u001b[33mpatch\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, **options)\n\u001b[32m   1250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:920\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[39m, in \u001b[36m_request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1003\u001b[39m log.debug(\n\u001b[32m   1004\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1005\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1009\u001b[39m     response.headers,\n\u001b[32m   1010\u001b[39m )\n\u001b[32m   1011\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1014\u001b[39m     response.raise_for_status()\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1062\u001b[39m, in \u001b[36m_retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1058\u001b[39m     log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m   1060\u001b[39m     time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_response\u001b[39m(\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1064\u001b[39m     *,\n\u001b[32m   1065\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1066\u001b[39m     options: FinalRequestOptions,\n\u001b[32m   1067\u001b[39m     response: httpx.Response,\n\u001b[32m   1068\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m   1069\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[Stream[Any]] | \u001b[38;5;28mtype\u001b[39m[AsyncStream[Any]] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1070\u001b[39m     retries_taken: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m   1071\u001b[39m ) -> ResponseT:\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.request.headers.get(RAW_RESPONSE_HEADER) == \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1073\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m   1074\u001b[39m             ResponseT,\n\u001b[32m   1075\u001b[39m             LegacyAPIResponse(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1083\u001b[39m             ),\n\u001b[32m   1084\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1013\u001b[39m, in \u001b[36m_request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1003\u001b[39m log.debug(\n\u001b[32m   1004\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m,\n\u001b[32m   1005\u001b[39m     request.method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1009\u001b[39m     response.headers,\n\u001b[32m   1010\u001b[39m )\n\u001b[32m   1011\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, response.headers.get(\u001b[33m\"\u001b[39m\u001b[33mx-request-id\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1014\u001b[39m     response.raise_for_status()\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1062\u001b[39m, in \u001b[36m_retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1058\u001b[39m     log.info(\u001b[33m\"\u001b[39m\u001b[33mRetrying request to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m%f\u001b[39;00m\u001b[33m seconds\u001b[39m\u001b[33m\"\u001b[39m, options.url, timeout)\n\u001b[32m   1060\u001b[39m     time.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1062\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_response\u001b[39m(\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1064\u001b[39m     *,\n\u001b[32m   1065\u001b[39m     cast_to: Type[ResponseT],\n\u001b[32m   1066\u001b[39m     options: FinalRequestOptions,\n\u001b[32m   1067\u001b[39m     response: httpx.Response,\n\u001b[32m   1068\u001b[39m     stream: \u001b[38;5;28mbool\u001b[39m,\n\u001b[32m   1069\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[Stream[Any]] | \u001b[38;5;28mtype\u001b[39m[AsyncStream[Any]] | \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1070\u001b[39m     retries_taken: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m   1071\u001b[39m ) -> ResponseT:\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response.request.headers.get(RAW_RESPONSE_HEADER) == \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1073\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m   1074\u001b[39m             ResponseT,\n\u001b[32m   1075\u001b[39m             LegacyAPIResponse(\n\u001b[32m   (...)\u001b[39m\u001b[32m   1083\u001b[39m             ),\n\u001b[32m   1084\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Ihno\\Hoger onderwijs\\UCLL\\Jaar 2\\Advanced AI\\semester project\\avanced_ai_semester_project\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1028\u001b[39m, in \u001b[36m_request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1020\u001b[39m     self._sleep_for_retry(\n\u001b[32m   1021\u001b[39m         retries_taken=retries_taken,\n\u001b[32m   1022\u001b[39m         max_retries=max_retries,\n\u001b[32m   1023\u001b[39m         options=input_options,\n\u001b[32m   1024\u001b[39m         response=response,\n\u001b[32m   1025\u001b[39m     )\n\u001b[32m   1026\u001b[39m     continue\n\u001b[32m-> \u001b[39m\u001b[32m1028\u001b[39m # If the response is streamed then we need to explicitly read the response\n\u001b[32m   1029\u001b[39m # to completion before attempting to access the response text.\n\u001b[32m   1030\u001b[39m if not err.response.is_closed:\n\u001b[32m   1031\u001b[39m     err.response.read()\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say hello\"}],\n",
    "    max_tokens=10\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make predictions or decisions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get the API key from environment variable\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ GOOGLE_API_KEY not found in .env file!\")\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# Make a request to Gemini\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probeersel met google AI of gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.169.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-generativeai) (2.40.0)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: pydantic in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.0rc0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai)\n",
      "  Using cached pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.0/1.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.0rc0-py3-none-any.whl (160 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading google_api_python_client-2.169.0-py3-none-any.whl (13.3 MB)\n",
      "   ---------------------------------------- 0.0/13.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.3 MB 5.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 2.4/13.3 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.4/13.3 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.5/13.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.5/13.3 MB 5.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 6.8/13.3 MB 5.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 7.9/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.2/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.2/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 12.3/13.3 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.3/13.3 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.71.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 2.1/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.4/4.3 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 5.5 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Using cached pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: uritemplate, pyparsing, protobuf, grpcio, proto-plus, httplib2, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc0 google-api-python-client-2.169.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 pyparsing-3.2.3 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1473fd30954873b3975b9dc2673489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='▶️ Action:', layout=Layout(width='70%'), placeholder='What does Ihno do next?')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ca76235c2341d0bd2e2ea8e0091b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d872f76dda4321a0b5ff39e4286950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- IMPORTS ---\n",
    "import os\n",
    "import time\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "\n",
    "# --- LOAD API KEY ---\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"❌ GOOGLE_API_KEY not found in .env file!\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# --- GAME STATE ---\n",
    "model_name = \"gemini-1.5-pro\"\n",
    "player_name = \"Ihno\"\n",
    "context = \"\"\n",
    "game_memory = []\n",
    "player_stats = {}\n",
    "inventory = []\n",
    "difficulty = 1\n",
    "\n",
    "# --- DIFFICULTY ADJUSTMENT ---\n",
    "def adjust_difficulty(player_input):\n",
    "    global difficulty\n",
    "    if any(word in player_input.lower() for word in [\"attack\", \"fight\", \"battle\"]):\n",
    "        difficulty = min(difficulty + 1, 5)\n",
    "    elif any(word in player_input.lower() for word in [\"run\", \"talk\", \"hide\"]):\n",
    "        difficulty = max(difficulty - 1, 1)\n",
    "    return difficulty\n",
    "\n",
    "# --- STORY GENERATION (Gemini) ---\n",
    "def generate_story(context, player_input, difficulty):\n",
    "    prompt = (\n",
    "        \"You are a fantasy storytelling AI. \"\n",
    "        \"Continue the adventure in a vivid, immersive style. \"\n",
    "        f\"Difficulty level: {difficulty}.\\n\\n\"\n",
    "        f\"{context}\\n\"\n",
    "        f\"{player_name}: {player_input}\\n\"\n",
    "        \"Narrator:\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name)\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error generating story: {e}\"\n",
    "\n",
    "# --- PRINT GAME STATE ---\n",
    "def print_game_state():\n",
    "    display(Markdown(f\"### 📖 **Story so far**\\n{context}\"))\n",
    "    display(Markdown(f\"**🧍 {player_name}'s Inventory:** {inventory}\"))\n",
    "    display(Markdown(f\"**❤️ Stats:** {player_stats} | 🎯 Difficulty:** {['Easy', 'Medium', 'Hard', 'Very Hard', 'Nightmare'][difficulty - 1]}\"))\n",
    "\n",
    "# --- PLAY TURN ---\n",
    "def play_turn(player_input):\n",
    "    global context\n",
    "    if not player_input.strip():\n",
    "        return\n",
    "    game_memory.append(f\"{player_name}: {player_input}\")\n",
    "    adjust_difficulty(player_input)\n",
    "\n",
    "    recent_context = \"\\n\".join(game_memory[-6:])\n",
    "    new_story = generate_story(recent_context, player_input, difficulty)\n",
    "    context_update = f\"\\n{player_name}: {player_input}\\n{new_story}\"\n",
    "    context += context_update\n",
    "    game_memory.append(new_story)\n",
    "\n",
    "    output_area.clear_output(wait=True)\n",
    "    with output_area:\n",
    "        print_game_state()\n",
    "\n",
    "# --- START GAME ---\n",
    "def start_new_game():\n",
    "    global context, player_stats, inventory, difficulty, game_memory\n",
    "    context = f\"{player_name} awakens in a dark forest. A mysterious figure approaches.\"\n",
    "    game_memory = [context]\n",
    "    player_stats = {\"health\": 100, \"strength\": 10, \"gold\": 5}\n",
    "    inventory = [\"torch\"]\n",
    "    difficulty = 1\n",
    "    output_area.clear_output()\n",
    "    with output_area:\n",
    "        display(Markdown(\"🆕 **New game started.**\"))\n",
    "        print_game_state()\n",
    "\n",
    "# --- UI SETUP ---\n",
    "input_box = widgets.Text(\n",
    "    placeholder='What does Ihno do next?',\n",
    "    description='▶️ Action:',\n",
    "    layout=widgets.Layout(width='70%')\n",
    ")\n",
    "submit_button = widgets.Button(description=\"Submit\", button_style='success')\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_button_click(b):\n",
    "    play_turn(input_box.value)\n",
    "    input_box.value = ''\n",
    "\n",
    "submit_button.on_click(on_button_click)\n",
    "\n",
    "# --- START & DISPLAY ---\n",
    "start_new_game()\n",
    "display(input_box, submit_button, output_area)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token conuter for prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from tiktoken) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\ihno\\hoger onderwijs\\ucll\\jaar 2\\advanced ai\\semester project\\avanced_ai_semester_project\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-win_amd64.whl (893 kB)\n",
      "   ---------------------------------------- 0.0/893.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 893.9/893.9 kB 5.1 MB/s eta 0:00:00\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in the prompt: 351\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Define the prompt text\n",
    "prompt_text = \"\"\"\n",
    "Ihno awakens in a dark forest. A mysterious figure approaches. Ihno: I talk with the mysterious figure. Narrator: The forest floor, a tapestry of damp earth and decaying leaves, pressed against Ihno's cheek. He blinked, disoriented, the canopy of interwoven branches obscuring the sky. Emerald twilight filtered through the leaves, painting the world in an ethereal green glow. He sat up, pushing himself to his feet, his head throbbing with a dull ache. He remembered nothing.\n",
    "\n",
    "A rustling in the undergrowth made him jump. A figure emerged from the shadows, its form cloaked in a dark, hooded robe that trailed along the forest floor. The hood obscured its face, leaving only a sliver of pale skin visible beneath. It carried a long, gnarled staff, its top carved into the shape of a crescent moon.\n",
    "\n",
    "The figure stopped a few paces from Ihno, silent and still. The air grew heavy with an unspoken magic.\n",
    "\n",
    "Ihno swallowed, his throat dry. \"Who are you?\" he asked, his voice a shaky whisper that seemed swallowed by the vastness of the woods.\n",
    "\n",
    "The figure raised a hand, a slow, deliberate movement. It pointed the staff towards a path barely discernible through the dense foliage. A faint, silvery light seemed to emanate from the staff's tip, illuminating the path like a moonbeam.\n",
    "\n",
    "A low, melodious voice, like the rustling of leaves in a gentle breeze, echoed around Ihno. \"The path awaits,\" it said. \"It will lead you to the answers you seek.\"\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the tokenizer for GPT models\n",
    "encoder = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Tokenize the text\n",
    "tokens = encoder.encode(prompt_text)\n",
    "\n",
    "# Count the number of tokens\n",
    "num_tokens = len(tokens)\n",
    "print(f\"Number of tokens in the prompt: {num_tokens}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
